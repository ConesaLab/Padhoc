"""
  Program:    Classes for working with parse graphs
  Date:       Jan. 31, 2008
  Author:     Jari Bjorne

  Description: This file contains classes and functions for working with
  sentence parse graphs. A parse graph can be created from interaction xml.
  The nodes can be modified and assigned attributes like weight, and the
  result can be converted into an adjacency matrix. The parse graph can
  also be used to generate different paths between its tokens.
                
  Status: All classes and methods should be working.

  Dependencies: PorterStemmer (CommonUtils/Stemming)
                Range.py (CommonUtils)
"""

import Utils.Libraries.PorterStemmer as stemmer
import Utils.Range as Range
import sys
        
class ParseGraphNode:
    """ 
    Represents a single node (either token or dependency) in the parse graph
    or a path generated by a ParseGraph-object.
    """
    def __init__(self, isDependency=False):
        self.isDependency = isDependency
        # token attributes
        self.pos = None
        self.text = None
        self.id = None
        self.charOffset = None
        self.dependencies = [] # all dependencies
        self.entities = [] # this token is part of these named entities
        # dependency attributes
        self.dependencyType = None
        self.fro = None # added to adjacency matrix labels
        self.to = None
    
    def toString(self, showPos=False, highlight=False):
        string = ""
        if self.isDependency:
            string = "-" + str(self.dependencyType) + "-"
        else:
            if showPos:
                string = "[" + self.pos + "]"
            else:
                string = "[" + self.text + "]"
        if highlight:
            string = "{" + string[1:-1] + "}"
        return string

class ParseGraph:
    """
    A ParseGraph-object consists of tokens and dependencies. A dependency connects
    two tokens with two edges (token->dependency->token, where -> = edge).
    """
    def __init__(self, tokenElements, dependencyElements, mergeDependencies=False):
        self.tokensById, self.dependenciesById = self.buildParseGraph(tokenElements, dependencyElements, mergeDependencies)
    
    ###########################################################################
    # Construction and Conversion
    ###########################################################################

    def buildParseGraph(self, tokenElements, dependencyElements, mergeDependencies=False):
        """ Returns dictionaries containing tokens and dependencies
        of the graph generated from ElementTree-elements.
        """
        tokensById = {}
        dependenciesById = {}
        for tokenElement in tokenElements:
            node = ParseGraphNode()
            node.id = int(tokenElement.attrib["id"].split("_")[1])
            node.pos = tokenElement.attrib["POS"]
            node.text = tokenElement.attrib["text"]
            charFrom, charTo = tokenElement.attrib["charOffset"].split("-")
            node.charOffset = (int(charFrom), int(charTo))
            tokensById[node.id] = node
    
        #self.depByOrder = []
        dependencyIndex = len(tokensById) + 99
        if mergeDependencies:
            dependenciesByFroAndTo = {}
        for dependencyElement in dependencyElements:
            dependency = ParseGraphNode(True)
            dependency.dependencyType = dependencyElement.attrib["type"]
            dependency.fro = tokensById[int(dependencyElement.attrib["t1"].split("_")[1])]
            dependency.to = tokensById[int(dependencyElement.attrib["t2"].split("_")[1])]
            
            if mergeDependencies:
                key = (dependency.fro.id, dependency.to.id) #frozenset([dependency.fro.id, dependency.to.id])
                if dependenciesByFroAndTo.has_key(key):
                    if not type(dependenciesByFroAndTo[key].dependencyType) == types.ListType:
                        dependenciesByFroAndTo[key].dependencyType = [dependenciesByFroAndTo[key].dependencyType]
                    dependenciesByFroAndTo[key].dependencyType.append(dependency.dependencyType)
                else:
                    dependenciesByFroAndTo[key] = dependency
                    tokensById[dependency.fro.id].dependencies.append(dependency)
                    tokensById[dependency.to.id].dependencies.append(dependency)
                    dependency.id = dependencyIndex
                    assert( not dependenciesById.has_key(dependency.id) )
                    dependenciesById[dependency.id] = dependency
            else:
                tokensById[dependency.fro.id].dependencies.append(dependency)
                tokensById[dependency.to.id].dependencies.append(dependency)
                #dependenciesById["dep_" + str(dependencyIndex) + "-mt_" + str(dependency.fro.id) + "-" + dependency.dependencyType + "-mt_" + str(dependency.to.id)] = dependency
                #dependenciesById[dependencyIndex] = dependency
                dependency.id = dependencyIndex # (dependency.fro.id,dependency.to.id)
                assert( not dependenciesById.has_key(dependency.id) )
                dependenciesById[dependency.id] = dependency
            dependencyIndex += 1
        
        return tokensById, dependenciesById

    ###########################################################################
    # Marking and manipulation of special tokens
    ###########################################################################
    
    def markNamedEntities(self, entityElements):
        """ Marks tokens belonging to named entities
        """
        namedEntityTokens = []
        for entityElement in entityElements:
            offsets = []
            offsetStrings = entityElement.attrib["charOffset"].split(",")
            for offsetString in offsetStrings:
                charFrom, charTo = offsetString.split("-")
                offset = (int(charFrom), int(charTo))
                offsets.append(offset)
            for k,v in self.tokensById.iteritems():
                for offset in offsets:
                    if Range.overlap(offset, v.charOffset):
                        v.entities.append(entityElement.attrib["id"])
                        namedEntityTokens.append(v.id)
        return namedEntityTokens

    def getNamedEntityTokenIds(self, namedEntityIds):
        """ Returns the ids of all tokens in specified named entities
        """
        tokenIds = []
        for key, node in self.tokensById.iteritems():
            for id in namedEntityIds:
                if id in node.entities:
                    tokenIds.append(node.id)
        return tokenIds
    
    def getTokenIdsByText(self, texts, lookInsideNamedEntities=False):
        """ Returns the ids of all tokens whose text attribute can be
        found in the list texts. Can be used f.e. detecting interaction
        words.
        """
        matchingTokens = []
        for node in self.tokensById.values():
            if len(node.entities) > 0 and not lookInsideNamedEntities:
                continue
            if node.text.lower() in texts:
                matchingTokens.append(node.id)
            elif node.text.find("-") != -1: # For cases like actin-activation
                tempText = node.text.rsplit("-",1)[1]
                if tempText.lower() in texts:
                    matchingTokens.append(node.id)
        return matchingTokens
    
    def stemTokens(self):
        for token in self.tokensById.values():
            token.stem = stemmer.stem(token.text)
    
    ###########################################################################
    # NetworkX-based shortest path
    ###########################################################################
    
    def buildNXGraph(self):
        """ Initializes the graph structure used by NetworkX.
        Called automatically when needed.
        """
        import networkx as NX
        self.nXGraph = NX.Graph()
        for token in self.tokensById.values():
            self.nXGraph.add_node(token.id)
        for dependency in self.dependenciesById.values(): #self.depByOrder:
            self.nXGraph.add_node(dependency.id)
            self.nXGraph.add_edge((dependency.fro.id,dependency.id))
            self.nXGraph.add_edge((dependency.id,dependency.to.id))

    def buildShortestPathNX(self, startTokenId, endTokenId, directed=False):
        """ Build shortest path using NetworkX
        """
        import networkx as NX
        if (not hasattr(self,"nXGraph")) or self.nXGraph == None:
            self.buildNXGraph()
        path = NX.shortest_path(self.nXGraph, startTokenId, endTokenId)
        if path == False:
            return []
        isTokenPhase = True
        for i in range(len(path)):
            if isTokenPhase:
                path[i] = self.tokensById[path[i]]
            else:
                path[i] = self.dependenciesById[path[i]]
            isTokenPhase = not isTokenPhase
        return path
